{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c91a1f7-1cc5-44ef-bb7c-fcc310a8d503",
   "metadata": {},
   "source": [
    "# WEB SCRAPING\n",
    "\n",
    "#### This code scrapes race results data from the Leipzig Marathon 'Ergebnis-Datenbank' (Results Databank). \n",
    "\n",
    "#### The browser:\n",
    "\n",
    "- Selects the year from a dropdown menu.  \n",
    "\n",
    "- Checks how many pages of results exist for that year.  \n",
    "\n",
    "- Scrapes the table data on each page and adds it to a CSV file.  \n",
    "\n",
    "- Clicks the 'Weiter' (Next) button to move through all year data has been scraped.\n",
    "\n",
    "- Then, the script moves on to the next year in the list and repeats the process.\n",
    "\n",
    "#### Note: The loop runs from index 1 to 46, which covers the years 1977 to 2024 (1999 and 2022 are missing from the data).\n",
    "\n",
    "#### There's a short delay after each interaction to avoid overloading the server or triggering bot protection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6b7865-ff38-4800-8e0b-f785ba136bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException, TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928b2b3b-9979-4cce-99ef-1939ca08cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver Setup\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_experimental_option(\"detach\", True)\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0\")\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.get(\"https://leipzigmarathon.de/ergebnis-suche/\")\n",
    "\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f5592a-d6b7-4618-8d57-a38ba98c62ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_of_clicks():\n",
    "    try:\n",
    "        # Wait up to 10 seconds for all visible pagination buttons to load\n",
    "        pagination_buttons = WebDriverWait(driver, 10).until(\n",
    "            EC.visibility_of_all_elements_located((By.CSS_SELECTOR, \".gridjs-pages button\"))\n",
    "        )\n",
    "        \n",
    "        # Get the text from each button, keeping only those that are digits\n",
    "        page_numbers = [button.text for button in pagination_buttons if button.text.isdigit()]\n",
    "        \n",
    "        # Return the highest page number found, or 0 if there are no page numbers\n",
    "        return int(page_numbers[-1]) if page_numbers else 0\n",
    "\n",
    "    except Exception:\n",
    "        # If anything goes wrong (e.g. buttons not found), return 0\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4fe464-9d30-40b5-a5c2-d2efb6256d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_with_retry(driver, button_aria_label, max_attempts=3):\n",
    "    # Try clicking the button up to 3 times\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            # Wait up to 10 seconds for the button to become clickable\n",
    "            next_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, f'button[aria-label=\"{button_aria_label}\"]'))\n",
    "            )\n",
    "            \n",
    "            # Click the button using JavaScript (more reliable than .click() on dynamic pages)\n",
    "            driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "            \n",
    "            # Wait 2 seconds after clicking to allow the page to update\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # Click was successful, return True\n",
    "            return True\n",
    "        \n",
    "        # If the button becomes stale or doesn't load in time, wait and try again\n",
    "        except (StaleElementReferenceException, TimeoutException):\n",
    "            time.sleep(2)\n",
    "\n",
    "    # If all attempts fail, return False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb7f00d-8b3c-4e88-b7b0-d497a297583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_table_data(year):\n",
    "    # Create the filename using the year\n",
    "    filename = f\"scraped_data_{year}.csv\"\n",
    "\n",
    "    # Open the file in append mode, with UTF-8 encoding and proper newline handling\n",
    "    with open(filename, \"a\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file, quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "        # If the file is empty, write the header row\n",
    "        if file.tell() == 0:\n",
    "            writer.writerow([\"Datum\", \"Wettbewerb\", \"PlatzGesamt\", \"Name\", \"Vorname\", \"Nettozeit\",\n",
    "                             \"Ort/Verein\", \"Nation\", \"Jahrgang\", \"Alterklasse\", \"PlatzAk\", \"Bruttozeit\"])\n",
    "\n",
    "        # Find all table rows on the current webpage\n",
    "        rows = driver.find_elements(By.XPATH, \"//table/tbody/tr\")\n",
    "        for row in rows:\n",
    "            # Get all columns (cells) in the current row\n",
    "            columns = row.find_elements(By.TAG_NAME, \"td\")\n",
    "\n",
    "            # Skip rows that don't contain real data\n",
    "            if len(columns) > 1:\n",
    "                wettbewerb = columns[1].text.strip()\n",
    "                \n",
    "                # Only process rows for the \"Marathon\" event\n",
    "                if wettbewerb == \"Marathon\":\n",
    "                    # Extract and clean text from each column\n",
    "                    row_data = [col.text.strip() for col in columns]\n",
    "\n",
    "                    # Ensure row_data has exactly 12 items, filling in blanks if needed\n",
    "                    row_data = row_data[:12] + [\"\"] * (12 - len(row_data))\n",
    "\n",
    "                    # Write the cleaned row to the CSV file\n",
    "                    writer.writerow(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3696e18-39cf-4032-b703-76b343a39d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_through_years_index():\n",
    "    start_year = 1977\n",
    "\n",
    "    # Loop through 46 years, starting from 1977\n",
    "    for i in range(1, 47):\n",
    "        current_year = start_year + (i - 1)\n",
    "\n",
    "        # Find the year dropdown and select the year by its index\n",
    "        years_element = driver.find_element(\"name\", \"wettkampf_select\")\n",
    "        dd = Select(years_element)\n",
    "        dd.select_by_index(i)\n",
    "        time.sleep(3)  # Wait for the page to load results for the selected year\n",
    "\n",
    "        # Calculate how many pages of results there are\n",
    "        total_pages = calculate_number_of_clicks()\n",
    "\n",
    "        # Loop through each page of results\n",
    "        for page_number in range(1, total_pages + 1):\n",
    "            # Scrape the table data for the current page and year\n",
    "            scrape_table_data(current_year)\n",
    "\n",
    "            # If there are more pages, click the \"Next\" button\n",
    "            if page_number < total_pages:\n",
    "                button_aria_label = \"Weiter\"\n",
    "                success = click_with_retry(driver, button_aria_label)\n",
    "                if not success:\n",
    "                    break  # Stop if unable to click \"Next\"\n",
    "\n",
    "            time.sleep(2)  # Wait before loading the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8d6cec-3130-44f4-9e9e-726665502586",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterate_through_years_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a634fb-aff2-4dc1-aeca-ccb00607e6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

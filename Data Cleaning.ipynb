{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35c184fa-37fc-42dc-877e-dbf25dd4a49f",
   "metadata": {},
   "source": [
    "# DATA CLEANING\n",
    "\n",
    "#### This notebook cleans the race results data scraped from the Leipzig Marathon 'Ergebnis-Datenbank' (Results Database).\n",
    "\n",
    "#### Multiple CSV files are imported and cleaned individually, then combined into a single CSV, ready for analysis in Tableau.\n",
    "\n",
    "#### Transformations Applied:\n",
    "\n",
    "- Converted Nettozeit (net time) into total seconds, compatible with Tableau\n",
    "- Renamed columns for consistency and clarity\n",
    "- Dropped unnecessary columns where necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be36920-a8cf-4b4b-b086-14eaf69196cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "897693b4-cde1-4ce2-935b-db318364dd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all race results csv files.\n",
    "\n",
    "csv_files = glob.glob('Leipzig/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c3dfb1-02ad-4890-ad81-844dc9e26042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sort the list in chronological order.\n",
    "\n",
    "csv_files_sorted = sorted(csv_files, key=lambda x: int(re.search(r'(\\d{4})', x).group()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8f67c2-57eb-4eea-a31f-8127b2ced757",
   "metadata": {},
   "source": [
    "#### Cleaning 'Datum' (Date) Column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd8ee9-ceab-4645-8075-8557818188cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by checking for any duplicate or incorrect values.\n",
    "\n",
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "    unique_datums = df['Datum'].unique()\n",
    "\n",
    "    print(unique_datums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ec2a2de-909f-4dba-85a8-809cb6c96e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Race results from 1999 are missing. Checked the website and confirmed that this data is missing, not a code problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d01a8296-000a-420c-b3fc-58631aede45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['28.04.2020' '28.04.2002' nan]\n"
     ]
    }
   ],
   "source": [
    "# Cleaning incorrect values from 2002. \n",
    "\n",
    "df = pd.read_csv(csv_files_sorted[24])\n",
    "\n",
    "unique_datums = df['Datum'].unique()\n",
    "\n",
    "print(unique_datums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f1be834-9321-4a4b-9c23-cf0d7111c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Datum'] = '28.04.2002'\n",
    "\n",
    "df.to_csv(csv_files_sorted[34], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4206877-e56c-489f-a247-9cf621f31bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'virtueller Lauf 2020' and '2021' data, as these years will be too different to compare meaningfully.\n",
    "\n",
    "csv_files_sorted.remove('Leipzig/scraped_data_2019.csv')\n",
    "csv_files_sorted.remove('Leipzig/scraped_data_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82fd9d6b-8450-4d22-b132-21a6ec1ed6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 2024 so that date is formatted consistently.\n",
    "\n",
    "df = pd.read_csv(csv_files_sorted[-1])\n",
    "\n",
    "df['Datum'] = '21.04.2024'\n",
    "\n",
    "df.to_csv(csv_files_sorted[-1], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcd512a-2509-4251-af3c-1fa5565a4873",
   "metadata": {},
   "source": [
    "#### Cleaning 'Wettbewerb' (Competition) Column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f4399ec-8c26-4956-9c93-c4e37136f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I want to make sure that all data is only related to the Marathon race.\n",
    "# This should have been taken care of during web scraping, but want to double check.\n",
    "# Trying to avoid data from other events, e.g. half marathon or 10km."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbec0a3a-b989-4331-99af-acc69bc3ff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "    unique_events = df['Wettbewerb'].unique()\n",
    "    \n",
    "    if len(unique_events) > 1:\n",
    "        print(f\"{file} has {len(unique_events)} unique Wettbewerb values: {unique_events}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0a62f9a-d4a6-4978-82aa-e45c62383388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results as expected, data is formatted correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accafd14-e392-4b56-bc1f-4c6d5b67268b",
   "metadata": {},
   "source": [
    "#### Cleaning 'Platz Gesamt' (Overall Placing) Column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8beaa219-7fd7-4be6-844d-f1342fd3f18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping this column, as I will be able to calculate this myself in Tableau based on the finishing times.\n",
    "# This will be more reliable, avoiding any transcription errors.\n",
    "\n",
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.drop(columns='PlatzGesamt')\n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f17774-efce-499f-ab7c-5d73c216be81",
   "metadata": {},
   "source": [
    "#### Cleaning Empty Column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d129af-0c23-4d21-b383-45dc71b7c52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    print(df['Name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b407daa2-a188-431a-a74e-12156f87ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This column is empty, so will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5577deae-0d10-4e8a-8dc5-7e8c6e3ef377",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "    df.drop(columns='Name', inplace=True)\n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ff5ff7-bb8b-489a-af0d-d467a1971f99",
   "metadata": {},
   "source": [
    "#### Cleaning Bib Number Column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b924cd9-8d1c-4762-8118-766d87b7c004",
   "metadata": {},
   "outputs": [],
   "source": [
    " for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    print(df['Vorname'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e826253-6424-4002-95ae-7508b03c8656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This seems to correspond to runner's bib numbers.\n",
    "# To confirm this, I searched for an image of the 2022 winner, Nic Ihlow.\n",
    "# His bib number was 40001, which agreed with the data.\n",
    "# This column can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4e14994-ec8e-46c0-8dcd-7e58beef45b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "    df.drop(columns='Vorname', inplace=True)\n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952aee7f-dd9c-44f9-84ab-f5ee1fabf0b0",
   "metadata": {},
   "source": [
    "#### Cleaning 'Name' (Last Name) Column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8d34b2-8d05-4050-ac4f-d6c3a2d36fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    print(df['Nettozeit'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80d64093-b55a-4b50-85c1-de5c8e1e4183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This column is incorrectly lablled 'Nettozeit' (Net Time), but actually refers to last name.\n",
    "# So will rename this column.\n",
    "\n",
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    df = df.rename(columns={'Nettozeit': 'Name'})\n",
    "\n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b290ec9d-73a5-46aa-af32-cad3201a29f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a NaN showing up, which should be cleaned.\n",
    "# Appears on only the first row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7a0a810e-258f-4174-8d13-4c5e645c2f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = csv_files_sorted[-2]\n",
    "df = pd.read_csv(file_path)\n",
    "df = df.iloc[1:]\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040e95ff-de0a-45a4-bf3d-41ed5d4e2f43",
   "metadata": {},
   "source": [
    "#### Cleaning 'Vorname' (First Name) Column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffb9cae-c303-4cdf-8313-8c98523070f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    print(df['Ort/Verein'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "afa0527e-345a-4f95-8c0c-c8a94742bcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This column is incorrectly lablled 'Nettozeit' (Net Time), but actually refers to last name.\n",
    "# So will rename this column.\n",
    "\n",
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    df = df.rename(columns={'Ort/Verein': 'Vorname'})\n",
    "\n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbc4d1f-293d-42ae-826a-fe5700043f33",
   "metadata": {},
   "source": [
    "#### Cleaning Empty Column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9106854a-d58b-4f1d-8a16-b7f4fa358e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    print(df['Nation'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "40a5fe1d-9806-49f1-87ad-343d28dbcf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "    df.drop(columns='Nation', inplace=True)\n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677abf87-c2ee-42e0-a143-824266f04d28",
   "metadata": {},
   "source": [
    "#### Cleaning Net Time Column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5499b9-ba3b-4080-97f7-a800f0cc9d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    print(df['Jahrgang'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b0d2dec1-ddf6-4ecf-9eb9-4ec9114ae46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This column is incorrectly lablled 'Jahrgang' (Age Cohort), but actually refers to net time.\n",
    "# So will rename this column.\n",
    "\n",
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    df = df.rename(columns={'Jahrgang': 'Nettozeit'})\n",
    "\n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5142ff93-d69d-4d62-bb73-682884cafdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will convert these times from hh:mm:ss format to seconds, as this makes it easier to work with in Tableau.\n",
    "# First, will need to ensure that all of these times are formatted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ff163d30-8329-42b2-b2b3-7b0a25d7491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I am performing three transformations:\n",
    "# Convert all semi-colon and comma symbols to colons.\n",
    "# Extract hh:mm:ss time\n",
    "# Strip leading zero from hours\n",
    "\n",
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    df['Nettozeit'] = df['Nettozeit'].astype(str).str.replace(';,', ':', regex=True)\n",
    "\n",
    "    df['Nettozeit'] = df['Nettozeit'].str.extract(r'(\\d{1,2}:\\d{2}:\\d{2})')\n",
    "\n",
    "    df['Nettozeit'] = df['Nettozeit'].str.replace(r'^0(?=\\d:)', '', regex=True)\n",
    "\n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8363db32-d436-4dfe-9558-d85841be56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    print(df['Nettozeit'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcd72f9-a25e-496e-8d92-1e3a3feec882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There might still be NaNs in the data, but I will treat these as DNFs (did not finish)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a85af917-9985-4ec8-abe8-88363112c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I will convert this hh:mm:ss format to seconds.\n",
    "\n",
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    df['Nettozeit'] = pd.to_timedelta(df['Nettozeit'], errors='coerce').dt.total_seconds()\n",
    "\n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ff6b52-f1ea-4b09-bd24-caf93b7e2659",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    print(df['Nettozeit'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14869b99-ba0a-494b-8168-4555e6ac03a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to manually check the conversion worked correctly for 2:37:07:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5cd92f02-d7e7-4322-ae56-ea6c60a9a00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9427"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * 3600 + 37 * 60 + 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0909a29-e622-46ae-b318-50ea182982ba",
   "metadata": {},
   "source": [
    "#### Cleaning Club Columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299f3d49-e131-49c4-8566-f8422eef57db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    print(df['Alterklasse'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a448c53e-734a-450b-8cd7-f2a893cc2ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This column is misnamed, actually refers to running club.\n",
    "# Decided to drop this.\n",
    "\n",
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "    df.drop(columns='Alterklasse', inplace=True)\n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c35d5-6911-4eb9-bef9-f6b19d474dfd",
   "metadata": {},
   "source": [
    "#### Cleaning Age Cohort Column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c60ce-e0be-45fa-8aff-ef7e38630cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    print(df['PlatzAk'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c7b0879a-5115-4888-bb02-e492a4c5042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This column is misnamed, actually refers to age cohort.\n",
    "\n",
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    df = df.rename(columns={'PlatzAk': 'Alterklasse'})\n",
    "\n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4784a52c-ecf8-4204-a33b-84deb7e6ff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    print(df['Alterklasse'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "88e94641-8ac7-452e-838c-c128a366c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to coerce invalid entries (like nationality) into NaNs.\n",
    "\n",
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "    df['Alterklasse'] = pd.to_numeric(df['Alterklasse'], errors='coerce')\n",
    "    \n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bbe5b9-2839-41d1-a60b-f36a90069c1e",
   "metadata": {},
   "source": [
    "#### Drop Age Groups Column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c039ec15-47f9-4332-9d8a-e676b244f324",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    print(df['Bruttozeit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fe2300-ac11-4cfa-aef8-ea1688c5aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have different age classes that were used within the first 10 years of the race.\n",
    "# But these are very inconsistent and it's hard to find the exact definitions online.\n",
    "# Also they are much less granular than age year, so I will just drop these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "797495ce-0fac-4dc6-9aa6-068006483631",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "    df.drop(columns='Bruttozeit', inplace=True)\n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fc6e5d-4fc1-4af0-8c53-66202b5dfa18",
   "metadata": {},
   "source": [
    "#### Merge all CSV files together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00e7912-deea-4844-86d6-09fae0c1b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final step in my data cleaning is to merge all the csvs together to make one list which can then be imported into Tableau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2644d378-73bf-401e-8e09-2c34c5b42da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for file in csv_files_sorted:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "combined_df.to_csv(\"final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0cde83-85ac-4622-b569-83a4c45ff46f",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
